# -*- coding: utf-8 -*-
"""
ä½¿ç”¨LLMè¿›è¡Œæ•°æ®å¢å¼ºçš„æ¨¡å—ï¼ŒåŒ…æ‹¬åˆ›å»ºå¢å¼ºçš„ä»£è¡¨æ€§æ ·æœ¬æ•°æ®é›†
"""
import argparse
from copy import error
import pandas as pd
import numpy as np
import sys
import os
import time
# sys.path.append(os.path.abspath('../cllm'))
# sys.path.append(os.path.abspath('.'))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)
from src.cllm.llm_gen2 import llm_gen_error_analysis
from src.cllm.llm_gen2 import llm_gen_table_ontology
from src.cllm.llm_gen2 import llm_gen_enhanced_clean_data
from src.cllm.llm_gen2 import llm_gen_inject_errors
from src.cllm.llm_gen2 import llm_gen_error_analysis_again
from .llm_clean_gen import enhance_clean_data_with_llm
from src.error_detection.llm_error_gen_one_to_one import inject_errors_with_llm_one_to_one
from src.error_detection.llm_error_gen_batch import inject_errors_with_llm_batch
from src.error_detection.dataset import Dataset
# from llm_gen2 import llm_gen_error_analysis
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import ResponseSchema, StructuredOutputParser

api_details = {
            "api_base": "https://jeniya.cn/v1",
            "api_version": "free",
            "api_key": "sk-9SSJQSfSLf7aUtfTCMhCgsxiw5deylXvOUuHtPCDDB3Sa1ds",
        }
model = "gpt-4o-mini"
llm_serving = "together"

def analyse_data_error(dataframe, clean_dataframe, save_path = None):
    """
    åˆ›å»ºç”¨äºé”™è¯¯ç±»å‹åˆ†æçš„å›ºå®šæ¨¡æ¿
    è¿”å›:
    - prompt: ChatPromptTemplateå¯¹è±¡
    - generator_template: æ¨¡æ¿å­—ç¬¦ä¸²
    - format_instructions: æ ¼å¼è¯´æ˜å­—ç¬¦ä¸²
    """
    # å®šä¹‰è¾“å‡ºç»“æ„ï¼ˆé”™è¯¯ç±»å‹ã€å—å½±å“åˆ—ã€æè¿°ï¼‰
    response_schemas = [
        ResponseSchema(name="error_type", description="é”™è¯¯çš„ç±»åˆ«ï¼Œä¾‹å¦‚æ‹¼å†™é”™è¯¯ã€æ ¼å¼é”™è¯¯ã€ç¼ºå¤±å€¼ã€æ•°å€¼å¼‚å¸¸ç­‰"),
        ResponseSchema(name="affected_columns", description="æ¶‰åŠçš„åˆ—ååˆ—è¡¨"),
        ResponseSchema(name="error_description", description="è¯¥é”™è¯¯ç±»å‹çš„è¯¦ç»†è¯´æ˜å’Œå…¸å‹è¡¨ç°å½¢å¼"),
    ]

    # åˆ›å»ºç»“æ„åŒ–è¾“å‡ºè§£æå™¨
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # å›ºå®šæ¨¡æ¿
    generator_template = """\
You are a data error analyst.
Your task is to analyze the differences between clean and dirty data examples and identify the major error types that appear.

I will give you two sets of data:
- Clean samples: correct data without errors
- Dirty samples: corresponding data with errors

Please analyze what kinds of errors appear, which columns are affected, and describe their characteristics.

Repair data examples:
{data}

{format_instructions}

Your analysis should summarize recurring error patterns across the samples.
Do not simply list differences cell by cell, but generalize them into error categories.
"""

    # åˆ›å»ºå¯ç”¨äºLLMçš„Promptå¯¹è±¡
    prompt = ChatPromptTemplate.from_template(generator_template)
    error_analysis = llm_gen_error_analysis(    
        prompt=prompt,
        generator_template=generator_template,
        clean_df=clean_dataframe,
        dirty_df=dataframe,
        api_details=api_details,
        format_instructions=format_instructions,
        llm_serving='together',
        model=model,
    )
    if not save_path is None:
        error_analysis.to_csv(save_path, index=False)
        print(f"Error analysis saved to: {save_path}")
    
    return error_analysis

def analyse_data_error_again(dataframe, clean_dataframe, error_analysis, save_path = None):
    """
    åˆ›å»ºç”¨äºé”™è¯¯ç±»å‹åˆ†æçš„å›ºå®šæ¨¡æ¿
    è¿”å›:
    - prompt: ChatPromptTemplateå¯¹è±¡
    - generator_template: æ¨¡æ¿å­—ç¬¦ä¸²
    - format_instructions: æ ¼å¼è¯´æ˜å­—ç¬¦ä¸²
    """
    # å®šä¹‰è¾“å‡ºç»“æ„ï¼ˆé”™è¯¯ç±»å‹ã€å—å½±å“åˆ—ã€æè¿°ï¼‰
    response_schemas = [
        ResponseSchema(name="error_type", description="é”™è¯¯çš„ç±»åˆ«ï¼Œä¾‹å¦‚æ‹¼å†™é”™è¯¯ã€æ ¼å¼é”™è¯¯ã€ç¼ºå¤±å€¼ã€æ•°å€¼å¼‚å¸¸ç­‰"),
        ResponseSchema(name="affected_columns", description="æ¶‰åŠçš„åˆ—ååˆ—è¡¨"),
        ResponseSchema(name="error_description", description="è¯¥é”™è¯¯ç±»å‹çš„è¯¦ç»†è¯´æ˜å’Œå…¸å‹è¡¨ç°å½¢å¼"),
    ]

    # åˆ›å»ºç»“æ„åŒ–è¾“å‡ºè§£æå™¨
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # å›ºå®šæ¨¡æ¿
    generator_template = """\
You are a data error analyst.

You have an existing error analysis table that summarizes previously discovered error types in a dataset.
Now, you are provided with *new repair data examples* (dirty vs. clean pairs).
Your goal is to **update** the existing analysis:
- Add **new error types** that were not previously identified.
- Modify existing descriptions **only when clearly more accurate or consistent** with the new samples.
- Keep all other existing error types unchanged.

Inputs:
1. Previous error analysis:
{old_error_analysis}

2. Repair data examples (dirty vs. clean):
{data}

{format_instructions}

Output a concise, integrated updated error analysis table.
Avoid duplication of similar error types; merge when applicable.
"""

    # åˆ›å»ºå¯ç”¨äºLLMçš„Promptå¯¹è±¡
    prompt = ChatPromptTemplate.from_template(generator_template)
    error_analysis = llm_gen_error_analysis_again(    
        prompt=prompt,
        generator_template=generator_template,
        clean_df=clean_dataframe,
        dirty_df=dataframe,
        old_error_analysis=error_analysis,
        api_details=api_details,
        format_instructions=format_instructions,
        llm_serving='together',
        model=model,
    )
    if not save_path is None:
        error_analysis.to_csv(save_path, index=False)
        print(f"Error analysis saved to: {save_path}")
    
    return error_analysis

def analyse_table_ontology(dataframe, save_path=None):
    """
    åˆ›å»ºç”¨äºåˆ†æè¡¨æ ¼ç»“æ„å’Œåˆ—é—´å…³ç³»ï¼ˆOntology Treeï¼‰çš„å›ºå®šæ¨¡æ¿ã€‚
    
    å‚æ•°:
    - dataframe: è¾“å…¥çš„DataFrame
    - save_path: å¦‚æœæä¾›ï¼Œå°†ç»“æœä¿å­˜ä¸ºæ–‡ä»¶
    
    è¿”å›:
    - ontology_result: DataFrameæ ¼å¼çš„æœ¬ä½“æ ‘ç»“æœ
    """
    # å®šä¹‰è¾“å‡ºç»“æ„
    response_schemas = [
        ResponseSchema(name="column_name", description="å½“å‰åˆ—çš„åç§°"),
        ResponseSchema(name="related_columns", description="ä¸è¯¥åˆ—å­˜åœ¨è¯­ä¹‰æˆ–ç»Ÿè®¡å…³ç³»çš„åˆ—åˆ—è¡¨"),
        ResponseSchema(name="relation_type", description="åˆ—ä¹‹é—´çš„å…³ç³»ç±»å‹ï¼Œä¾‹å¦‚ï¼šä¾èµ–ã€å±‚çº§ã€èšåˆã€å¤–é”®ã€åŒä¹‰å­—æ®µç­‰"),
        ResponseSchema(name="relation_description", description="è¿™ç§å…³ç³»çš„ç®€çŸ­è¯´æ˜ï¼Œè§£é‡Šåˆ—é—´çš„è¯­ä¹‰æˆ–ç»Ÿè®¡è”ç³»"),
    ]

    # ç»“æ„åŒ–è§£æå™¨
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # === å›ºå®šæ¨¡æ¿ ===
    generator_template = """\
You are a data ontology constructor.
Your goal is to analyze the given tabular data and infer relationships among its columns.

I will provide a small table sample with column names and several rows of data.

Please analyze the following:
1. What kinds of relationships exist among columns (hierarchical, dependency, correlation, aggregation, etc.)
2. For each column, identify its related columns and describe how they are related.
3. Summarize relationships as structured ontology entries.

Table sample:
{data}

{format_instructions}

Important:
- Output should describe relationships among columns, not row-level values.
- Be concise but informative in your relation_description.
- Do not invent columns not present in the input.
"""

    # === åˆ›å»º Prompt ===
    prompt = ChatPromptTemplate.from_template(generator_template)

    # === è°ƒç”¨LLMç”Ÿæˆæœ¬ä½“æ ‘ ===
    ontology_result = llm_gen_table_ontology(
        prompt=prompt,
        generator_template=generator_template,
        dataframe=dataframe,
        format_instructions=format_instructions,
        llm_serving="together",
        api_details=api_details,
        model=model
    )

    # === ä¿å­˜ç»“æœ ===
    if save_path is not None:
        ontology_result.to_csv(save_path, index=False)
        print(f"âœ… Ontology analysis saved to: {save_path}")

    return ontology_result

def enhance_clean_data(clean_dataframe, ontology_dataframe, number=200, save_path=None):
    """
    ä½¿ç”¨LLMæ ¹æ®è¡¨æ ¼æœ¬ä½“æ ‘å’Œç¤ºä¾‹å¹²å‡€æ•°æ®ç”Ÿæˆå¢å¼ºçš„å¹²å‡€æ•°æ®
    
    å‚æ•°:
    - clean_dataframe: åŸå§‹å¹²å‡€æ•°æ® DataFrame
    - ontology_dataframe: è¡¨æ ¼æœ¬ä½“æ ‘ DataFrameï¼ˆåŒ…å«åˆ—å…³ç³»ä¸è¯­ä¹‰ä¿¡æ¯ï¼‰
    - number: è¦ç”Ÿæˆçš„å¢å¼ºæ ·æœ¬æ•°é‡
    - save_path: ä¿å­˜ç”Ÿæˆæ•°æ®çš„CSVè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
    - enhanced_clean_df: å¢å¼ºåçš„å¹²å‡€æ•°æ® DataFrame
    """
    # === Step 1. å®šä¹‰è¾“å‡ºæ ¼å¼ ===
    response_schemas = [
        ResponseSchema(name=col, description=f"Synthetic clean value for column '{col}'")
        for col in clean_dataframe.columns
    ]
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # === Step 2. æ„é€ ç”Ÿæˆæ¨¡æ¿ ===
    generator_template = """\
You are a professional data synthesizer.
Your goal is to generate **new clean tabular data samples** that are realistic and consistent with the given data schema and ontology.

### Given:
- Example clean data samples: {data}
- Table ontology describing column meanings and relations: {ontology}

### Instructions:
- Maintain data realism and column relationships as defined in ontology.
- Keep data free from errors, missing values, or contradictions.
- Ensure distribution and formats are consistent with given examples.
- Do NOT repeat the same rows from examples â€” generate novel but valid clean data.
- Return {number} rows of new clean data.

{format_instructions}

Generate enhanced clean tabular data that respects the ontology and examples.
Output exactly the structured clean data records in JSON format.
"""

    prompt = ChatPromptTemplate.from_template(template=generator_template)

    all_results = []
    generated_count = 0
    iteration = 0

    # === Step 3. è°ƒç”¨LLMç”Ÿæˆå¢å¼ºæ•°æ® ===
    while generated_count < number:
        iteration += 1
        remaining = number - generated_count
        current_batch = min(100, remaining)

        print(f"ğŸš€ Iteration {iteration}: Generating {current_batch} new clean samples "
              f"({generated_count}/{number} done)...")

        df_batch = llm_gen_enhanced_clean_data(
            prompt=prompt,
            generator_template=generator_template,
            format_instructions=format_instructions,
            clean_df=clean_dataframe,
            ontology_df=ontology_dataframe,
            llm_serving='together',
            api_details=api_details,
            number=current_batch,
            model=model,
        )

        # æ¸…ç†ç©ºç»“æœ
        if df_batch is not None and not df_batch.empty:
            all_results.append(df_batch)
            generated_count += len(df_batch)
        else:
            print("âš ï¸ LLM returned no valid data, retrying...")

        time.sleep(2)

    # === Step 5. åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ ===
    enhanced_df = pd.concat(all_results, ignore_index=True)

    # === Step 4. ä¿å­˜ç»“æœ ===
    if save_path is not None:
        enhanced_df.to_csv(save_path, index=False)
        print(f"âœ… Enhanced clean data saved to: {save_path}")

    print(f"ğŸ¯ Successfully generated {len(enhanced_df)} enhanced clean samples.")
    return enhanced_df

def inject_errors(clean_dataframe, error_analysis, batch_size=10, save_path=None):
    """
    å¾ªç¯è°ƒç”¨ LLMï¼Œæ ¹æ® error_analysis ä¸­çš„é”™è¯¯æ¨¡å¼å¯¹ clean_dataframe æ³¨å…¥ç›¸ä¼¼é”™è¯¯ã€‚
    ç”Ÿæˆå¯¹åº”æ•°é‡çš„è„æ•°æ® DataFrameã€‚

    å‚æ•°:
    - clean_dataframe: å¹²å‡€æ•°æ® DataFrame
    - error_analysis: DataFrameï¼ŒåŒ…å« error_type / affected_columns / error_description
    - batch_size: æ¯æ¬¡è°ƒç”¨ LLM ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ï¼Œé»˜è®¤ä¸º 10
    - save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
    - dirty_df: æ³¨å…¥é”™è¯¯åçš„è„æ•°æ® DataFrame
    """
    """
    - clean_dataframe: å¹²å‡€æ•°æ® DataFrame
    - error_analysis: DataFrameï¼ŒåŒ…å« error_type / affected_columns / error_description
    - save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
    - dirty_df: æ³¨å…¥é”™è¯¯åçš„è„æ•°æ® DataFrame
    """

    number = len(clean_dataframe)
    clean_dataframe = clean_dataframe.copy()
    clean_dataframe.insert(0, "row_index", range(len(clean_dataframe)))
    # === Step 1. å®šä¹‰è¾“å‡ºç»“æ„ ===
    response_schemas = [
        ResponseSchema(name=col, description=f"Value for column '{col}' after error injection")
        for col in clean_dataframe.columns
    ]
    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
    format_instructions = output_parser.get_format_instructions()

    # === Step 2. å®šä¹‰æç¤ºè¯æ¨¡æ¿ ===
    generator_template = """\
You are a **data error injector**.

Your mission: inject realistic, diverse, and context-aware errors into clean tabular data so that
the resulting dirty dataset simulates both (A) the *known* error patterns and (B) *plausible* errors
that were NOT listed in the provided analysis.

--- INPUTS (available to you):
- Clean data (tabular JSON): {data}
- Reference error patterns (examples / analysis): {error_patterns}

--- GLOBAL RULES:
1. **One dirty record per clean record** (strict 1-to-1 mapping).
2. Preserve **row order** and keep the `row_index` field exactly unchanged for alignment.
3. Do **not** add/delete/reorder rows or add any extra identifier fields (except keep `row_index` unchanged).
4. Preserve column names and schema (same number of columns and types).
5. Output **only** pure JSON (no commentary), a list of objects, each matching one input row.

--- ERROR INJECTION ALLOCATION (strict):
- For the set of modified cells across the whole batch, you must split injected errors into two equal halves:
  * **50%** must be errors *derived from* the provided `error_patterns` (follow their style/characteristics).
  * **50%** must be **LLM-inferred/plausible** errors applied to columns **not** necessarily listed in `error_patterns`.
- This 50/50 split should hold approximately for each output batch you generate (if batch is small, hold to per-row as closely as possible).

--- PER-ROW INJECTION RULES:
- For each input row, inject **multiple errors** (not just one) â€” e.g., modify **2â€“4 cells per row** where reasonable. If a row is very short, inject at least 1 cell.
- At least **one** of the modified cells per row should come from the *pattern-based* half (i.e., follow `error_patterns` when applicable), and at least **one** should be LLM-inferred (i.e., a plausible error extrapolated/applied to other columns).
- If `error_patterns` do not mention any columns that exist in a row, still apply **plausible** errors to that row (LLM-inferred half must still be honored).

--- GUIDELINES FOR LLM-INFERRED ERRORS:
- Consider column semantics when inventing errors:
  * Names/strings â†’ typos, capitalization changes, swapped tokens, missing prefixes/suffixes.
  * Addresses/cities â†’ abbreviations, swapped components, punctuation errors.
  * Dates â†’ alternate formats, off-by-one days, truncated year, swapped day/month.
  * Numeric â†’ rounding, extra digits, decimal/locale mismatches, sign errors.
  * Categorical â†’ label swap, missing/unknown tokens, truncated label.
- You may generalize patterns from one column to similar columns (e.g., a "name" typo pattern may also apply to "city", "address", "contact").
- Keep values **plausible** â€” don't produce nonsense tokens that would be obviously invalid for the column.

--- FORMAT & STABILITY:
- **Do not** add any new columns (e.g., do not add `row_index_copy`); keep schema identical.
- If you need to reference a row for alignment in the prompt, rely on the `row_index` already present â€” but **do not** output any new alignment fields.
- Output must be a JSON array of objects. Each object must have exactly the same keys (columns) as the input row and appear in the same order.

### Output:
Return the output in **JSON format**, as a list of objects.
Each object represents one dirty record and appears in the same order as the input.

{format_instructions}

"""




    prompt = ChatPromptTemplate.from_template(generator_template)

    # === Step 3. åˆå§‹åŒ–å¾ªç¯å˜é‡ ===
    all_results = []
    generated_count = 0
    iteration = 0

    while generated_count < number:
        iteration += 1
        remaining = number - generated_count
        current_batch = min(batch_size, remaining)

        print(f"ğŸš€ Iteration {iteration}: injecting errors for {current_batch} samples "
              f"({generated_count}/{number} done)...")

        df_batch = llm_gen_inject_errors(
            prompt=prompt,
            generator_template=generator_template,
            format_instructions=format_instructions,
            clean_df=clean_dataframe[generated_count:generated_count + current_batch],
            error_analysis_df=error_analysis,
            llm_serving=llm_serving,
            api_details=api_details,
            n_samples=current_batch,
            model=model,
        )

        if df_batch is not None and not df_batch.empty:
            all_results.append(df_batch)
            generated_count += len(df_batch)
        else:
            print("âš ï¸ LLM returned empty batch, retrying...")

        time.sleep(2)

    dirty_df = pd.concat(all_results, ignore_index=True)

    if "row_index" in dirty_df.columns:
        dirty_df = dirty_df.sort_values(by="row_index").reset_index(drop=True)
        dirty_df = dirty_df.drop(columns=["row_index"], errors="ignore")

    if save_path is not None:
        dirty_df.to_csv(save_path, index=False)
        print(f"âœ… Dirty data saved to: {save_path}")

    print(f"ğŸ¯ Successfully generated {len(dirty_df)} dirty samples.")
    return dirty_df

def create_enhanced_representative_samples(representative_samples_dataset = None, representative_clean_path = None, 
                                         representative_dirty_path = None, dataset_name=None, n_samples=1000,
                                         api_details=None, llm_serving='together',
                                         model='gpt-3.5-turbo'):
    """
    åˆ›å»ºå¢å¼ºçš„ä»£è¡¨æ€§æ ·æœ¬æ•°æ®é›†
    
    å‚æ•°:
    - representative_samples_dataset: å·²ç»åŒ…å«è„æ•°æ®å’Œå¹²å‡€æ•°æ®çš„ä»£è¡¨æ€§æ ·æœ¬Datasetå®ä¾‹
    - n_samples: è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡
    - api_details: APIè¯¦ç»†ä¿¡æ¯
    - llm_serving: LLMæœåŠ¡ç±»å‹
    - model: ä½¿ç”¨çš„æ¨¡å‹
    
    è¿”å›:
    - å¢å¼ºåçš„ä»£è¡¨æ€§æ ·æœ¬Datasetå®ä¾‹
    """
    if api_details is None:
        api_details = {
            "api_base": "https://sg.uiuiapi.com/v1",
            "api_version": "uiui",
            "api_key": "sk-pJXuMXNJJ0jin4umqzadRm1rADF1i7aRrxpd3GTvmsUDbUEw",
        }
    
    # è·å–åŸå§‹çš„å¹²å‡€æ•°æ®å’Œè„æ•°æ®
    if not representative_samples_dataset is None:
        original_clean_data = representative_samples_dataset.clean_dataframe
        original_dirty_data = representative_samples_dataset.dataframe
        dataset_name = representative_samples_dataset.name
    elif not (representative_clean_path is None and representative_dirty_path is None):
        original_clean_data = pd.read_csv(representative_clean_path, dtype=object)
        original_dirty_data = pd.read_csv(representative_dirty_path, dtype=object)
    
    
    # è®¡ç®—éœ€è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ï¼ˆæ€»æ ·æœ¬æ•° - åŸå§‹æ ·æœ¬æ•°ï¼‰
    n_enhanced_samples = n_samples - len(original_clean_data)
    
    if n_enhanced_samples <= 0:
        print("No need to generate enhanced samples, using original samples only")
        return representative_samples_dataset
    
    print(f"Generating {n_enhanced_samples} enhanced samples to reach total of {n_samples} samples...")
    
    # ä½¿ç”¨LLMç”ŸæˆæŒ‡å®šæ•°é‡çš„å¹²å‡€æ•°æ®
    print("Generating clean data with LLM...")
    enhanced_clean_data = enhance_clean_data_with_llm(
        clean_dataframe=original_clean_data,
        dataset_name=dataset_name,
        api_details=api_details,
        llm_serving=llm_serving,
        model=model,
        n_samples=n_enhanced_samples,
    )
    
    # ä¸ºç”Ÿæˆçš„å¹²å‡€æ•°æ®æ³¨å…¥é”™è¯¯ï¼Œç¡®ä¿ä¸€ä¸€å¯¹åº”
    print("Injecting errors with LLM using batch processing...")
    enhanced_dirty_data = inject_errors_with_llm_batch(
        clean_dataframe=enhanced_clean_data,
        dataset_name=dataset_name,
        api_details=api_details,
        llm_serving=llm_serving,
        model=model,
        batch_size=20,  # ä½¿ç”¨æ‰¹æ¬¡å¤§å°20ä»¥ç¡®ä¿ä¸¥æ ¼çš„ä¸€ä¸€å¯¹åº”
        original_dirty_data=original_dirty_data  # ä¼ é€’åŸå§‹è„æ•°æ®ç”¨äºæ‹¼æ¥
    )
    
    # ç¡®ä¿å¢å¼ºçš„å¹²å‡€æ•°æ®å’Œè„æ•°æ®è¡Œæ•°ç›¸åŒ
    if len(enhanced_clean_data) != len(enhanced_dirty_data):
        print(f"Warning: Enhanced clean data ({len(enhanced_clean_data)}) and dirty data ({len(enhanced_dirty_data)}) have different row counts")
        # å–è¾ƒå°çš„è¡Œæ•°ä»¥ç¡®ä¿ä¸€ä¸€å¯¹åº”
        min_rows = min(len(enhanced_clean_data), len(enhanced_dirty_data))
        enhanced_clean_data = enhanced_clean_data.iloc[:min_rows]
        enhanced_dirty_data = enhanced_dirty_data.iloc[:min_rows]
        print(f"Adjusted to {min_rows} rows to ensure correspondence")
    
    # å°†åŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®æ‹¼æ¥åœ¨ä¸€èµ·
    final_clean_data = pd.concat([original_clean_data, enhanced_clean_data], ignore_index=True)
    final_dirty_data = pd.concat([original_dirty_data, enhanced_dirty_data], ignore_index=True)
    
    # ç¡®ä¿æœ€ç»ˆæ•°æ®é›†çš„è¡Œæ•°ç­‰äºn_samples
    if len(final_clean_data) > n_samples:
        final_clean_data = final_clean_data.iloc[:n_samples]
        final_dirty_data = final_dirty_data.iloc[:n_samples]
    
    print(f"Final dataset size: {len(final_clean_data)} samples")
    
    # åˆ›å»ºæ–°çš„Datasetå®ä¾‹
    enhanced_dataset_dict = {
        "name": f"enhanced_{representative_samples_dataset.name}",
        "path": representative_samples_dataset.path  # ä½¿ç”¨åŸå§‹è·¯å¾„ï¼Œä½†å®é™…æ•°æ®å°†è¢«æ›¿æ¢
    }
    enhanced_dataset = Dataset(enhanced_dataset_dict)
    enhanced_dataset.dataframe = final_dirty_data
    enhanced_dataset.clean_dataframe = final_clean_data
    
    # ä¿å­˜å¢å¼ºçš„å¹²å‡€æ•°æ®å’Œè„æ•°æ®åˆ°CSVæ–‡ä»¶
    # è·å–æ•°æ®é›†åç§°å’Œè·¯å¾„
    dataset_name = representative_samples_dataset.name
    base_path = os.path.dirname(representative_samples_dataset.path)
    
    # åˆ›å»ºä¿å­˜è·¯å¾„
    clean_data_path = os.path.join(base_path, "..", "enhanced_data", f"enhanced_clean_data_{dataset_name}_{n_samples}.csv")
    dirty_data_path = os.path.join(base_path, "..", "enhanced_data", f"enhanced_dirty_data_{dataset_name}_{n_samples}.csv")

    # ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
    print(f"Saving enhanced clean data to: {clean_data_path}")
    final_clean_data.to_csv(clean_data_path, index=False)
    
    print(f"Saving enhanced dirty data to: {dirty_data_path}")
    final_dirty_data.to_csv(dirty_data_path, index=False)
    
    print(f"Enhanced data saved successfully")
    
    return enhanced_dataset

if __name__ == "__main__":
    dirty_df = pd.read_csv("/home/stu/pys/CLLM-main/data/error_detection/hospital/dirty.csv", dtype=object)
    clean_df = pd.read_csv("/home/stu/pys/CLLM-main/data/error_detection/hospital/clean.csv", dtype=object)
    save_path = "/home/stu/pys/CLLM-main/data/error_detection/error.csv"
    error = analyse_data_error(dirty_df[:5], clean_df[:5], save_path=save_path)
    print("Error Analysis Result:")
    print(error)
    